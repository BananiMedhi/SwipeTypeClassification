{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from urllib.parse import unquote\n",
    "import pandas as pd\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential      \n",
    "from keras.layers import Dense           \n",
    "from keras.layers import LSTM            \n",
    "from keras.layers.embeddings import Embedding \n",
    "from keras.preprocessing import sequence\n",
    "from sklearn import preprocessing\n",
    "from flask import Flask, request \n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function is used to normalise the values. \n",
    "def normalize(arr):\n",
    "    return [(float(i)-min(arr))/(max(arr)-min(arr)) for i in arr]\n",
    "\n",
    "# The array is formatted and the class labels are extracted from the array.\n",
    "\n",
    "def formatArray(arr):\n",
    "    last = arr[len(arr)-1]\n",
    "    content = last.split(\"//\")\n",
    "    arr[len(arr)-1] = content[0]\n",
    "    return arr,int(content[1])\n",
    "\n",
    "# \n",
    "def readFile(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    varrr = []\n",
    "    classLabel = []\n",
    "    for i in content:\n",
    "        str_v = i.split(\",\")\n",
    "        str_v,label = formatArray(str_v)\n",
    "        str_v = [int(el) for el in str_v]\n",
    "        str_v = normalize(str_v)\n",
    "        vv=str(str_v).strip('[]')\n",
    "        vv=vv.replace(',','')\n",
    "        varrr.append(vv)\n",
    "        classLabel.append(label)\n",
    "    return varrr,classLabel\n",
    "def readData():\n",
    "    df = pd.DataFrame()\n",
    "    fname1 = \"lr.txt\"\n",
    "    fname2 = \"td.txt\"\n",
    "    classLabel = []\n",
    "    varrr = []\n",
    "    var,clabel = readFile(fname1)\n",
    "    varrr+=var\n",
    "    classLabel+=clabel\n",
    "    var,clabel = readFile(fname2)\n",
    "    varrr+=var\n",
    "    classLabel+=clabel\n",
    "    classLabel  = np.array(classLabel)\n",
    "    df['sequence'] = pd.Series(varrr).str.join('')\n",
    "    df['sequence'] = df['sequence'].apply(lambda x: [float(e) for e in x.split()])\n",
    "    train_size = int(len(df) * (1))\n",
    "    X_train = df['sequence'].values[:train_size]\n",
    "    return (X_train,classLabel),(X_train,classLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lstm model is trained and the model object is used to predict the class for the test data.\n",
    "def load_model():\n",
    "    (X_train, y_train) , (X_test, y_test) = readData()\n",
    "    max_review_length = 100\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=max_review_length,dtype='float32')\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=max_review_length,dtype='float32')\n",
    "    print(X_train)\n",
    "    embedding_vecor_length = 32\n",
    "    global model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5000, embedding_vecor_length, input_length=100))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=50)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.08333334 0.08333334]\n",
      " [0.         0.         0.         ... 0.03571429 0.03571429 0.03571429]\n",
      " [0.         0.         0.         ... 0.03703704 0.         0.01851852]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.9512195  0.9634146  0.9390244 ]\n",
      " [0.         0.         0.         ... 0.9746835  0.96202534 0.93670887]\n",
      " [0.         0.         0.         ... 0.92941177 0.9529412  0.9411765 ]]\n",
      "Epoch 1/10\n",
      "598/598 [==============================] - 2s 3ms/step - loss: 0.6925 - acc: 0.5284\n",
      "Epoch 2/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.6875 - acc: 0.5602\n",
      "Epoch 3/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.6730 - acc: 0.5769\n",
      "Epoch 4/10\n",
      "598/598 [==============================] - 1s 1ms/step - loss: 0.6025 - acc: 0.7542\n",
      "Epoch 5/10\n",
      "598/598 [==============================] - 1s 1ms/step - loss: 0.5231 - acc: 0.9197\n",
      "Epoch 6/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.4104 - acc: 0.9348\n",
      "Epoch 7/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.3027 - acc: 0.9381\n",
      "Epoch 8/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.2297 - acc: 0.9365\n",
      "Epoch 9/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.2132 - acc: 0.9415\n",
      "Epoch 10/10\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 0.2004 - acc: 0.9398\n",
      "Accuracy: 94.98%\n"
     ]
    }
   ],
   "source": [
    "load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/testClass\")\n",
    "def index1():\n",
    "    global model\n",
    "    n = request.args.get(\"param\")\n",
    "    n = n[1:-1]\n",
    "    n = [int(x) for x in n.split(\",\")]\n",
    "    print(n)\n",
    "    n = normalize(n)\n",
    "    Xnew = [n]\n",
    "\n",
    "    Xnew = sequence.pad_sequences(Xnew, maxlen=100,dtype='float32')\n",
    "    print(Xnew)\n",
    "    ynew = model.predict_classes(Xnew)\n",
    "    print(ynew)\n",
    "    return str(ynew[0][0])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
